---
title: "Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings"
collection: publications
category: conferences
date: 2025-12-04
venue: 'Advances in Neural Information Processing Systems (NeurIPS)'
award: "(Spotlight)"
authors: 'Evan Markou, Thalaiyasingam Ajanthan, and Stephen Gould' 
thumbnail: '/images/paper-template.png' # Placeholder image
paperurl: 'https://evanmarkou.github.io/files/2025-neurips-reductionmappings.pdf'
abstract: 'Many high-dimensional optimisation problems exhibit rich geometric structures in their set of minimisers, often forming smooth manifolds due to over-parametrisation or symmetries. When this structure is known, at least locally, it can be exploited through reduction mappings that reparametrise part of the parameter space to lie on the solution manifold. These reductions naturally arise from inner optimisation problems and effectively remove redundant directions, yielding a lower-dimensional objective. In this work, we introduce a general framework to understand how such reductions influence the optimisation landscape. We show that well-designed reduction mappings improve curvature properties of the objective, leading to better-conditioned problems and theoretically faster convergence for gradient-based methods. Our analysis unifies a range of scenarios where structural information at optimality is leveraged to accelerate convergence, offering a principled explanation for the empirical gains observed in such optimisation algorithms.'
bibtex: |-
    @inproceedings{markou2025reductionmappings,
    author    = {Evan Markou and
                Thalaiyasingam Ajanthan and
                Stephen Gould},
    title     = {Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings},
    booktitle = {NeurIPS},
    year      = {2025}}
---
