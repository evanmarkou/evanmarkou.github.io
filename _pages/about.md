---
permalink: /
title: "Welcome!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a third-year PhD student at the Australian National University, focusing on theoretical machine learning and deep learning theory. I am very grateful to be supervised by [Stephen Gould](https://users.cecs.anu.edu.au/~sgould/), [Thalaiyasingam Ajanthan](https://tajanthan.github.io/), and [Marcus Hutter](https://www.hutter1.net/index.htm). Prior to my PhD, I earned a Master's in Machine Learning and Computer Vision from ANU, where I worked on adversarial machine learning and [deep declarative networks](https://github.com/anucvml/ddn) under the supervision of [Stephen Gould](https://users.cecs.anu.edu.au/~sgould/). I also hold a Bachelor of Science (BSc Hons) in Computer Science from Harokopio University of Athens, where I did research on emotion recognition and affective computing using deep learning under [Dimitrios Michail](https://d-michail.github.io/) and [Iraklis Varlamis](https://varlamis.dit.people.hua.gr/).

My research lies at the intersection of deep learning, optimisation, and geometry, with an emphasis on building a more rigorous theoretical understanding of neural networks.

### Core Research Interests

* **The Geometry of Deep Learning:** I analyse the geometric structure of the loss landscape and solution space in deep neural networks. My goal is to characterise the properties of optimal solutions in over-parameterised models using tools from differential geometry and [frame theory](https://en.wikipedia.org/wiki/Frame_(linear_algebra)).

* **Optimisation and Convergence:** I derive convergence guarantees for non-convex optimisation problems in neural networks. My work explores how geometric conditions on the manifold of minimisers can be leveraged to design more efficient and reliable training algorithms.

*   **Generalisation and Occam's Razor:** My research connects the principle of [Occam's Razor](https://en.wikipedia.org/wiki/Occam's_razor) to how and why neural networks generalise. I develop novel bounds by measuring the algorithmic complexity of learned functions, using tools from [algorithmic information theory](https://en.wikipedia.org/wiki/Algorithmic_information_theory) and topology to analyse the structure of their decision boundaries.

I am always open to new collaborations. If you are interested in working together, please feel free to get in touch.

## News
{% include news.html id="about-news" visible_count=5 %}